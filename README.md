# ğŸ¡ King County House Price Prediction (2014â€“2015)

Exploring housing market dynamics in King County (Seattle area) by analyzing property features and predicting sale prices using Machine Learning models.  

---

## ğŸ“Š Dataset Description
**Source:** King County house sales dataset (2014â€“2015)  
**Size:** ~21,000 records, 21 features  

**Key Variables:**
- `id` â€” Unique house identifier  
- `date` â€” Sale date  
- `price` â€” Sale price (**target variable**)  
- `bedrooms` â€” Number of bedrooms  
- `bathrooms` â€” Number of bathrooms (per bedroom basis)  
- `sqft_living` â€” Interior living space (sq. ft.)  
- `sqft_lot` â€” Land space (sq. ft.)  
- `floors` â€” Number of floors  
- `waterfront` â€” Whether house has waterfront view  
- `view` â€” View rating  
- `condition` â€” Overall house condition  
- `grade` â€” King County grading system  
- `sqft_above` â€” Sq. ft. above basement  
- `sqft_basement` â€” Basement area (sq. ft.)  
- `yr_built` â€” Year built  
- `yr_renovated` â€” Year renovated  
- `zipcode` â€” ZIP code  
- `lat` / `long` â€” Coordinates  
- `sqft_living15` â€” Living space of nearest 15 neighbors (2015)  
- `sqft_lot15` â€” Lot size of nearest 15 neighbors (2015)  

**Target â†’** `price`  
- Primary focus: Identify which features most strongly impact house prices.  
- Additional focus: Houses valued at **$650K+** for premium property insights.  

---

## ğŸ¯ Research Goals
- Which features most influence house sale prices?  
- How accurately can we predict house prices with ML models?  
- What differences emerge when analyzing premium homes ($650K+)?  

---

## ğŸ” Methodology

### 1. Data Cleaning
- Standardized column names  
- Fixed data types  
- Handled missing values  
- Removed extreme outliers  

### 2. Exploratory Data Analysis (EDA)
- Price distribution, feature correlations, and outlier detection  
- Heatmaps, bar plots, scatter plots for feature relationships  
- Segmentation of premium vs non-premium houses  

### 3. Modeling & Evaluation
- **Baseline Models:** Linear, Ridge, Lasso, KNN, Decision Tree, Ensemble Methods  
- **Feature Engineering:** Scaling, transformations, categorical encoding  
- **Model Comparison:** XGBoost, Random Forest, Gradient Boosting performed best  
- **Metrics Used:** RÂ² (Train/Test), RMSE  

---

## ğŸ“Œ Key Findings
- **Top drivers:** `grade`, `sqft_living`, location (`lat`, `long`, `zipcode`)  
- **Model performance:**
  - Ensemble methods (XGBoost, Random Forest, Gradient Boosting) achieved highest predictive power  
  - Linear/Ridge/Lasso models showed better generalization after feature engineering  
  - AdaBoost and Decision Tree underperformed (underfitting/overfitting issues)  
- **Premium homes ($650K+):** Stronger influence from `waterfront`, `view`, and `location`  

---

## âš™ï¸ How to Reproduce

### Prerequisites
- Python **3.9+**  
- `pip` and `virtualenv`/`venv` recommended  

### Setup
```bash
# Clone repository
git clone https://github.com/yourusername/kingcounty-houseprices.git
cd kingcounty-houseprices

# Create virtual environment
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

## â–¶ï¸ Run Analysis
1. Open **`EDA_house_prices.ipynb`** in Jupyter Notebook or JupyterLab  
2. Execute all cells to reproduce results  
3. Visualizations are saved in `figures/`  

---

## ğŸš€ Next Steps
- Hyperparameter tuning for XGBoost and Random Forest (already partially explored)  
- Build a production-ready price prediction API  
- Incorporate time-series trends (seasonality of sales)  
- Expand dataset with external features (schools, crime rates, economic indicators)  

